{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVl2Gu7sBPPG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResBlockUp(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.upsample = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.upsample(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1),   # [64,16,16]\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # [128,8,8]\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),  # [128,8,8]\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            ResBlockUp(128, 64),      # [64,16,16]\n",
        "            ResBlockUp(64, 32),       # [32,32,32]\n",
        "            nn.Conv2d(32, 3, kernel_size=3, padding=1),  # Final color output\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMEZzRRqBWXm"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(4, 64, kernel_size=4, stride=2, padding=1),  # 1 (gray) + 3 (color)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # [256, 4, 4]\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 4 * 4, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, gray, color):\n",
        "        x = torch.cat([gray, color], dim=1)  # Concatenate on channel dimension\n",
        "        return self.model(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMoRHVD0Bb9A",
        "outputId": "258a6d52-2cf3-4375-ebab-c5134f4a5215"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import ToTensor, ToPILImage, Grayscale\n",
        "\n",
        "# Custom Dataset that returns: grayscale image, color image\n",
        "class CIFAR10GrayColor(Dataset):\n",
        "    def __init__(self, train=True):\n",
        "        self.dataset = datasets.CIFAR10(\n",
        "            root='./data',\n",
        "            train=train,\n",
        "            download=True,\n",
        "            transform=transforms.ToTensor()\n",
        "        )\n",
        "        self.to_gray = transforms.Grayscale(num_output_channels=1)\n",
        "        self.to_pil = ToPILImage()\n",
        "        self.to_tensor = ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        color_img, _ = self.dataset[idx]  # [3,32,32]\n",
        "        pil_img = self.to_pil(color_img)  # Convert back to PIL\n",
        "        gray_img = self.to_gray(pil_img)  # [1,32,32]\n",
        "        gray_img = self.to_tensor(gray_img)\n",
        "\n",
        "        return gray_img, color_img\n",
        "\n",
        "# Create train/test dataloaders\n",
        "train_dataset = CIFAR10GrayColor(train=True)\n",
        "test_dataset = CIFAR10GrayColor(train=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Example batch\n",
        "gray_batch, color_batch = next(iter(train_loader))\n",
        "print(\"Grayscale batch shape:\", gray_batch.shape)  # [64, 1, 32, 32]\n",
        "print(\"Color batch shape:\", color_batch.shape)     # [64, 3, 32, 32]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9uMyVPH5BxVf",
        "outputId": "58f208d1-28a1-4c96-8186-1958006c4b1e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_epochs = 50\n",
        "criterion_gan = nn.BCELoss()   #uncomment if running from scratch\n",
        "criterion_l1 = nn.L1Loss()\n",
        "\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "lambda_l1 = 100\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    g_gan_loss_epoch = 0.0\n",
        "    g_l1_loss_epoch = 0.0\n",
        "    g_total_loss_epoch = 0.0\n",
        "    d_loss_epoch = 0.0\n",
        "\n",
        "    for batch_idx, (gray, color) in enumerate(train_loader):\n",
        "        gray = gray.to(device)\n",
        "        color = color.to(device)\n",
        "\n",
        "        real_labels = torch.full((gray.size(0), 1), 0.9, device=device)  # Label smoothing\n",
        "        fake_labels = torch.zeros((gray.size(0), 1), device=device)\n",
        "\n",
        "        # --- Train Discriminator every alternate step ---\n",
        "        if batch_idx % 2 == 0:\n",
        "            optimizer_d.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                fake_color = generator(gray)\n",
        "\n",
        "            real_output = discriminator(gray, color)\n",
        "            fake_output = discriminator(gray, fake_color)\n",
        "\n",
        "            d_loss_real = criterion_gan(real_output, real_labels)\n",
        "            d_loss_fake = criterion_gan(fake_output, fake_labels)\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "        else:\n",
        "            d_loss = torch.tensor(0.0)\n",
        "\n",
        "        # --- Train Generator (twice per batch) ---\n",
        "        g_gan_loss = g_l1_loss = g_total_loss = 0.0\n",
        "        for _ in range(2):\n",
        "            optimizer_g.zero_grad()\n",
        "            fake_color = generator(gray)\n",
        "            output = discriminator(gray, fake_color)\n",
        "\n",
        "            g_gan = criterion_gan(output, real_labels)\n",
        "            g_l1 = criterion_l1(fake_color, color)\n",
        "            g_total = g_gan + lambda_l1 * g_l1\n",
        "\n",
        "            g_total.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "            g_gan_loss += g_gan.item()\n",
        "            g_l1_loss += g_l1.item()\n",
        "            g_total_loss += g_total.item()\n",
        "\n",
        "        g_gan_loss_epoch += g_gan_loss / 2\n",
        "        g_l1_loss_epoch += g_l1_loss / 2\n",
        "        g_total_loss_epoch += g_total_loss / 2\n",
        "        d_loss_epoch += d_loss.item()\n",
        "\n",
        "        # --- Print percentage progress ---\n",
        "        percent = 100 * (batch_idx + 1) / len(train_loader)\n",
        "        print(f\"\\rEpoch [{epoch+51}/{num_epochs+50}] Progress: {percent:.2f}%\", end='', flush=True)\n",
        "\n",
        "    # --- Epoch Summary ---\n",
        "    avg_d = d_loss_epoch / len(train_loader)\n",
        "    avg_gg = g_gan_loss_epoch / len(train_loader)\n",
        "    avg_l1 = g_l1_loss_epoch / len(train_loader)\n",
        "    avg_gtotal = g_total_loss_epoch / len(train_loader)\n",
        "\n",
        "    print(f\"\\n\\n=== Epoch [{epoch+1}/{num_epochs}] Summary ===\")\n",
        "    print(f\"Discriminator Loss: {avg_d:.4f}\")\n",
        "    print(f\"Generator GAN Loss: {avg_gg:.4f}\")\n",
        "    print(f\"Generator L1 Loss : {avg_l1:.4f}\")\n",
        "    print(f\"Generator Total Loss (GAN + L1): {avg_gtotal:.4f}\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    # --- Visualize Samples ---\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_gray = gray[0].unsqueeze(0).to(device)\n",
        "        sample_real_color = color[0].cpu()\n",
        "        sample_fake_color = generator(sample_gray).squeeze(0).cpu()\n",
        "\n",
        "        sample_gray_show = sample_gray.squeeze(0).repeat(3, 1, 1).cpu()\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
        "        axs[0].imshow(sample_real_color.permute(1, 2, 0))\n",
        "        axs[0].set_title(\"Actual Colored Image\")\n",
        "        axs[0].axis('off')\n",
        "\n",
        "        axs[1].imshow(sample_gray_show.permute(1, 2, 0), cmap='gray')\n",
        "        axs[1].set_title(\"Grayscale Input\")\n",
        "        axs[1].axis('off')\n",
        "\n",
        "        axs[2].imshow(sample_fake_color.permute(1, 2, 0).clip(0, 1))\n",
        "        axs[2].set_title(\"Recolored by Generator\")\n",
        "        axs[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    generator.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhNrHXFLDOB9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def visualize_recolor_samples(generator, train_loader, test_loader, use_train=True, num_samples=4, device=None):\n",
        "    generator.eval()\n",
        "\n",
        "    loader = train_loader if use_train else test_loader\n",
        "    data_iter = iter(loader)\n",
        "\n",
        "    try:\n",
        "        gray_imgs, color_imgs = next(data_iter)\n",
        "    except StopIteration:\n",
        "        print(\"Empty loader!\")\n",
        "        return\n",
        "\n",
        "    # Take only the first few samples\n",
        "    gray_imgs = gray_imgs[:num_samples].to(device)\n",
        "    color_imgs = color_imgs[:num_samples].to(device)\n",
        "\n",
        "    # Ensure grayscale input has correct shape: [B, 1, H, W]\n",
        "    if gray_imgs.ndim == 3:\n",
        "        gray_imgs = gray_imgs.unsqueeze(1)  # add channel dimension if missing\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake_color_imgs = generator(gray_imgs).cpu()\n",
        "\n",
        "    gray_imgs = gray_imgs.cpu()\n",
        "    color_imgs = color_imgs.cpu()\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "        axs[0].imshow(color_imgs[i].permute(1, 2, 0).clip(0, 1))\n",
        "        axs[0].set_title(\"Actual Colored Image\")\n",
        "        axs[0].axis('off')\n",
        "\n",
        "        axs[1].imshow(gray_imgs[i][0], cmap='gray')\n",
        "        axs[1].set_title(\"Grayscale Input\")\n",
        "        axs[1].axis('off')\n",
        "\n",
        "        axs[2].imshow(fake_color_imgs[i].permute(1, 2, 0).clip(0, 1))\n",
        "        axs[2].set_title(\"Recolored by Generator\")\n",
        "        axs[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    generator.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gIf_TvQoE7Al",
        "outputId": "8b377af2-396f-497e-e94e-1ff2c8599321"
      },
      "outputs": [],
      "source": [
        "visualize_recolor_samples(generator, train_loader, test_loader, use_train=False, num_samples=50, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PLKBVx6wJT0C",
        "outputId": "cf194d5e-0102-4a69-8d7a-6d6411299761"
      },
      "outputs": [],
      "source": [
        "# Save locally\n",
        "torch.save(generator.state_dict(), f'generator_epoch{epoch+1}.pth')\n",
        "torch.save(discriminator.state_dict(), f'discriminator_epoch{epoch+1}.pth')\n",
        "from google.colab import files\n",
        "\n",
        "# Download to local machine\n",
        "files.download(f'generator_epoch{epoch+1}.pth')\n",
        "files.download(f'discriminator_epoch{epoch+1}.pth')\n",
        "# Save checkpoint\n",
        "torch.save({\n",
        "    'epoch': epoch+1,\n",
        "    'generator_state_dict': generator.state_dict(),\n",
        "    'discriminator_state_dict': discriminator.state_dict(),\n",
        "    'optimizer_g_state_dict': optimizer_g.state_dict(),\n",
        "    'optimizer_d_state_dict': optimizer_d.state_dict(),\n",
        "}, f'model_checkpoint_epoch{epoch+1}.pth')\n",
        "\n",
        "# Download\n",
        "files.download(f'model_checkpoint_epoch{epoch+1}.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m0U2a1_nSLzI",
        "outputId": "74d0ec93-b73e-43b0-c12e-59c53c971556"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_epochs = 100\n",
        "# criterion_gan = nn.BCELoss()   #uncomment if running from scratch\n",
        "# criterion_l1 = nn.L1Loss()\n",
        "\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "lambda_l1 = 250\n",
        "\n",
        "#generator = Generator().to(device)\n",
        "#discriminator = Discriminator().to(device)\n",
        "\n",
        "#optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "#optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    g_gan_loss_epoch = 0.0\n",
        "    g_l1_loss_epoch = 0.0\n",
        "    g_total_loss_epoch = 0.0\n",
        "    d_loss_epoch = 0.0\n",
        "\n",
        "    for batch_idx, (gray, color) in enumerate(train_loader):\n",
        "        gray = gray.to(device)\n",
        "        color = color.to(device)\n",
        "\n",
        "        real_labels = torch.full((gray.size(0), 1), 0.9, device=device)  # Label smoothing\n",
        "        fake_labels = torch.zeros((gray.size(0), 1), device=device)\n",
        "\n",
        "        # --- Train Discriminator every alternate step ---\n",
        "        if batch_idx % 2 == 0:\n",
        "            optimizer_d.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                fake_color = generator(gray)\n",
        "\n",
        "            real_output = discriminator(gray, color)\n",
        "            fake_output = discriminator(gray, fake_color)\n",
        "\n",
        "            d_loss_real = criterion_gan(real_output, real_labels)\n",
        "            d_loss_fake = criterion_gan(fake_output, fake_labels)\n",
        "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
        "            d_loss.backward()\n",
        "            optimizer_d.step()\n",
        "        else:\n",
        "            d_loss = torch.tensor(0.0)\n",
        "\n",
        "        # --- Train Generator (twice per batch) ---\n",
        "        g_gan_loss = g_l1_loss = g_total_loss = 0.0\n",
        "        for _ in range(2):\n",
        "            optimizer_g.zero_grad()\n",
        "            fake_color = generator(gray)\n",
        "            output = discriminator(gray, fake_color)\n",
        "\n",
        "            g_gan = criterion_gan(output, real_labels)\n",
        "            g_l1 = criterion_l1(fake_color, color)\n",
        "            g_total = g_gan + lambda_l1 * g_l1\n",
        "\n",
        "            g_total.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "            g_gan_loss += g_gan.item()\n",
        "            g_l1_loss += g_l1.item()\n",
        "            g_total_loss += g_total.item()\n",
        "\n",
        "        g_gan_loss_epoch += g_gan_loss / 2\n",
        "        g_l1_loss_epoch += g_l1_loss / 2\n",
        "        g_total_loss_epoch += g_total_loss / 2\n",
        "        d_loss_epoch += d_loss.item()\n",
        "\n",
        "        # --- Print percentage progress ---\n",
        "        percent = 100 * (batch_idx + 1) / len(train_loader)\n",
        "        print(f\"\\rEpoch [{epoch+101}/{num_epochs+100}] Progress: {percent:.2f}%\", end='', flush=True)\n",
        "\n",
        "    # --- Epoch Summary ---\n",
        "    avg_d = d_loss_epoch / len(train_loader)\n",
        "    avg_gg = g_gan_loss_epoch / len(train_loader)\n",
        "    avg_l1 = g_l1_loss_epoch / len(train_loader)\n",
        "    avg_gtotal = g_total_loss_epoch / len(train_loader)\n",
        "\n",
        "    print(f\"\\n\\n=== Epoch [{epoch+1}/{num_epochs}] Summary ===\")\n",
        "    print(f\"Discriminator Loss: {avg_d:.4f}\")\n",
        "    print(f\"Generator GAN Loss: {avg_gg:.4f}\")\n",
        "    print(f\"Generator L1 Loss : {avg_l1:.4f}\")\n",
        "    print(f\"Generator Total Loss (GAN + L1): {avg_gtotal:.4f}\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    # --- Visualize Samples ---\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_gray = gray[0].unsqueeze(0).to(device)\n",
        "        sample_real_color = color[0].cpu()\n",
        "        sample_fake_color = generator(sample_gray).squeeze(0).cpu()\n",
        "\n",
        "        sample_gray_show = sample_gray.squeeze(0).repeat(3, 1, 1).cpu()\n",
        "\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
        "        axs[0].imshow(sample_real_color.permute(1, 2, 0))\n",
        "        axs[0].set_title(\"Actual Colored Image\")\n",
        "        axs[0].axis('off')\n",
        "\n",
        "        axs[1].imshow(sample_gray_show.permute(1, 2, 0), cmap='gray')\n",
        "        axs[1].set_title(\"Grayscale Input\")\n",
        "        axs[1].axis('off')\n",
        "\n",
        "        axs[2].imshow(sample_fake_color.permute(1, 2, 0).clip(0, 1))\n",
        "        axs[2].set_title(\"Recolored by Generator\")\n",
        "        axs[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    generator.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RoBmAOf4SY0L",
        "outputId": "6d490573-56dd-405e-b7e9-77de66c20db1"
      },
      "outputs": [],
      "source": [
        "# Save locally\n",
        "torch.save(generator.state_dict(), f'generator_epoch{epoch+1}.pth')\n",
        "torch.save(discriminator.state_dict(), f'discriminator_epoch{epoch+1}.pth')\n",
        "from google.colab import files\n",
        "\n",
        "# Download to local machine\n",
        "files.download(f'generator_epoch{epoch+1}.pth')\n",
        "files.download(f'discriminator_epoch{epoch+1}.pth')\n",
        "# Save checkpoint\n",
        "torch.save({\n",
        "    'epoch': epoch+1,\n",
        "    'generator_state_dict': generator.state_dict(),\n",
        "    'discriminator_state_dict': discriminator.state_dict(),\n",
        "    'optimizer_g_state_dict': optimizer_g.state_dict(),\n",
        "    'optimizer_d_state_dict': optimizer_d.state_dict(),\n",
        "}, f'model_checkpoint_epoch{epoch+1}.pth')\n",
        "\n",
        "# Download\n",
        "files.download(f'model_checkpoint_epoch{epoch+1}.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
